{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import labrary\n",
    "from __future__ import print_function, division\n",
    "from builtins import range, input\n",
    "\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, AveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path dataset\n",
    "covid_path = '/content/drive/MyDrive/Colab Notebooks/Xray dataset/COVID-19'\n",
    "noncovid_path = '/content/drive/MyDrive/Colab Notebooks/Xray dataset/Normal'\n",
    "\n",
    "# Mengambil gambar dari path \n",
    "covid_files = glob(covid_path + '/*')\n",
    "noncovid_files = glob(noncovid_path + '/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing labels \n",
    "covid_labels = []\n",
    "noncovid_labels = []\n",
    "\n",
    "covid_images=[]\n",
    "noncovid_images=[]\n",
    "\n",
    "import cv2 \n",
    "\n",
    "#resize dan memberikan label pada dataset\n",
    "for i in range(len(covid_files)):\n",
    "  image = cv2.imread(covid_files[i])\n",
    "  image = cv2.resize(image,(224,224))\n",
    "  covid_images.append(image)\n",
    "  covid_labels.append('Chest_COVID')\n",
    "for i in range(len(noncovid_files)):\n",
    "  image = cv2.imread(noncovid_files[i])\n",
    "  image = cv2.resize(image,(224,224))\n",
    "  noncovid_images.append(image)\n",
    "  noncovid_labels.append('Chest_NonCOVID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan gambar dataset covid dan noncovid secara acak\n",
    "def plot_images(images, title):\n",
    "    nrows, ncols = 5, 8\n",
    "    figsize = [10, 6]\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize, facecolor=(1, 1, 1))\n",
    "\n",
    "    for i, axi in enumerate(ax.flat):\n",
    "        axi.imshow(images[i])\n",
    "        axi.set_axis_off()\n",
    "\n",
    "    plt.suptitle(title, fontsize=24)\n",
    "    plt.tight_layout(pad=0.2, rect=[0, 0, 1, 0.9])\n",
    "    plt.show()\n",
    "plot_images(covid_images, 'Positive COVID-19 Chest X-ray')\n",
    "plot_images(noncovid_images, 'Negative COVID-19 Chest X-ray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalisasi [0,1]\n",
    "#covid_images = np.array(covid_images) / 255\n",
    "#noncovid_images = np.array(noncovid_images) / 255\n",
    "\n",
    "\n",
    "#normalisasi [-1,1]\n",
    "covid_images_norm=[]\n",
    "noncovid_images_norm=[]\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "for i in range(len(covid_images)):\n",
    "  imagenorm = []\n",
    "  for j in np.array(covid_images[i]):\n",
    "    partimage = (np.array(scaler.fit_transform(j)))\n",
    "    imagenorm.append(partimage)\n",
    "  covid_images_norm.append(np.array(imagenorm))\n",
    "\n",
    "for i in range(len(noncovid_images)):\n",
    "  imagenorm = []\n",
    "  for j in np.array(noncovid_images[i]):\n",
    "    partimage = (np.array(scaler.fit_transform(j)))\n",
    "    imagenorm.append(partimage)\n",
    "  noncovid_images_norm.append(imagenorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentasi dataset\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rotation_range=30,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# split into training and testing\n",
    "covid_x_train, covid_x_test, covid_y_train, covid_y_test = train_test_split(\n",
    "    covid_images_norm, covid_labels, test_size=0.3)\n",
    "noncovid_x_train, noncovid_x_test, noncovid_y_train, noncovid_y_test = train_test_split(\n",
    "    noncovid_images_norm, noncovid_labels, test_size=0.3)\n",
    "\n",
    "covid_x_train, covid_x_val, covid_y_train, covid_y_val = train_test_split(\n",
    "    covid_x_train, covid_y_train, test_size=0.2)\n",
    "noncovid_x_train, noncovid_x_val, noncovid_y_train, noncovid_y_val = train_test_split(\n",
    "    noncovid_x_train, noncovid_y_train, test_size=0.2)\n",
    "\n",
    "X_train = np.concatenate((noncovid_x_train, covid_x_train), axis=0)\n",
    "X_test = np.concatenate((noncovid_x_test, covid_x_test), axis=0)\n",
    "y_train = np.concatenate((noncovid_y_train, covid_y_train), axis=0)\n",
    "y_test = np.concatenate((noncovid_y_test, covid_y_test), axis=0)\n",
    "X_val = np.concatenate((noncovid_x_val, covid_x_val), axis=0)\n",
    "y_val = np.concatenate((noncovid_y_val, covid_y_val), axis=0)\n",
    "\n",
    "#Membuat label menjadi 0 atau 1\n",
    "y_train = LabelBinarizer().fit_transform(y_train)\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "y_test = LabelBinarizer().fit_transform(y_test)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "y_val = LabelBinarizer().fit_transform(y_val)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Membuat model xception\n",
    "xception = Xception(weights=\"imagenet\", include_top=False,\n",
    "    input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "outputs = xception.output\n",
    "outputs = Flatten(name=\"flatten\")(outputs)\n",
    "outputs = Dense(128, activation='relu')(outputs)\n",
    "outputs = Dense(2, activation='softmax')(outputs)\n",
    "\n",
    "model = Model(inputs=xception.input, outputs=outputs)\n",
    "\n",
    "for layer in xception.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "#Compile Model\n",
    "model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer='adam', \n",
    "        metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "history = model.fit(train_datagen.flow(X_train, y_train, batch_size=32),\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    validation_steps=len(X_val) / 32,\n",
    "                    steps_per_epoch=len(X_train) / 32,\n",
    "                    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "model.save('/content/drive/My Drive/Colab Notebooks/xception_chest.h5')\n",
    "#save the weight of model\n",
    "model.save_weights('/content/drive/My Drive/Colab Notebooks/xceptionweights_chest.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "model = load_model('/content/drive/My Drive/Colab Notebooks/xception_chest.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#membuat prediksi model\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisasi 5 prediksi\n",
    "prediction=y_pred[0:5]\n",
    "for index, probability in enumerate(prediction):\n",
    "  if probability[1] > 0.5:\n",
    "        plt.title('%.2f' % (probability[1]*100) + '% COVID')\n",
    "  else:\n",
    "        plt.title('%.2f' % ((1-probability[1])*100) + '% NonCOVID')\n",
    "  plt.imshow(X_test[index])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Binary classes\n",
    "y_pred_bin = np.argmax(y_pred, axis=1)\n",
    "y_test_bin = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot confusion matrix\n",
    "def plot_confusion_matrix(normalize):\n",
    "  classes = ['COVID','NonCOVID']\n",
    "  tick_marks = [0.5,1.5]\n",
    "  cn = confusion_matrix(y_test_bin, y_pred_bin,normalize=normalize)\n",
    "  sns.heatmap(cn,cmap='plasma',annot=True)\n",
    "  plt.xticks(tick_marks, classes)\n",
    "  plt.yticks(tick_marks, classes)\n",
    "  plt.title('Confusion Matrix')\n",
    "  plt.ylabel('True label')\n",
    "  plt.xlabel('Predicted label')\n",
    "  plt.show()\n",
    "\n",
    "print('Confusion Matrix without Normalization')\n",
    "plot_confusion_matrix(normalize=None)\n",
    "\n",
    "print('Confusion Matrix with Normalized Values')\n",
    "plot_confusion_matrix(normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_bin, y_pred_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy and loss plots\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.legend(['Training', 'Testing'])\n",
    "plt.savefig('xception_chest_accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.legend(['Training', 'Testing'])\n",
    "plt.savefig('xception_chest_loss.png')\n",
    "plt.show()"
   ]
  }
 ]
}